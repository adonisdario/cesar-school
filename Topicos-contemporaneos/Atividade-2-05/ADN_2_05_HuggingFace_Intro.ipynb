{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYnpPjpoui-o"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMsSEBgrui-p"
      },
      "source": [
        "# Utilizando Modelos Pré-treinados com HuggingFace\n",
        "\n",
        "Hugging Face é uma plataforma que oferece uma ampla variedade de modelos pré-treinados para tarefas de processamento de linguagem natural (NLP). Usar esses modelos permite que você aplique técnicas avançadas de NLP sem precisar treinar um modelo do zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8mpXPD6ui-q"
      },
      "source": [
        "## Tokenizadores\n",
        "\n",
        "Tokenização é o processo de converter texto em tokens, que são as unidades básicas que os modelos de NLP processam. A Hugging Face fornece tokenizadores para diferentes modelos, que geram tokens compatíveis com o modelo que será utilizado.\n",
        "\n",
        "Nesta seção, aprenderemos como carregar e utilizar tokenizadores com Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9zJreIEui-r"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, BertTokenizer\n",
        "\n",
        "# Carregando tokenizadores para GPT-2 e BERT\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2jCZhDcui-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c84c82-01fd-494d-e8f2-ef6bdd46db0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens GPT-2: ['Art', 'ificial', 'Ġintelligence', 'Ġis', 'Ġthe', 'Ġfuture', '.']\n",
            "Tokens BERT: ['artificial', 'intelligence', 'is', 'the', 'future', '.']\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de tokenização\n",
        "input_text = \"Artificial intelligence is the future.\"\n",
        "gpt2_tokens = gpt2_tokenizer.tokenize(input_text)\n",
        "bert_tokens = bert_tokenizer.tokenize(input_text)\n",
        "\n",
        "print(f\"Tokens GPT-2: {gpt2_tokens}\")\n",
        "print(f\"Tokens BERT: {bert_tokens}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa9DU-1mui-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078a75ca-e6b5-445e-acba-93c02a6de5df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDs GPT-2: [8001, 9542, 4430, 318, 262, 2003, 13]\n",
            "IDs BERT: [7976, 4454, 2003, 1996, 2925, 1012]\n"
          ]
        }
      ],
      "source": [
        "gpt2_ids = gpt2_tokenizer.convert_tokens_to_ids(gpt2_tokens)\n",
        "bert_ids = bert_tokenizer.convert_tokens_to_ids(bert_tokens)\n",
        "\n",
        "print(f\"IDs GPT-2: {gpt2_ids}\")\n",
        "print(f\"IDs BERT: {bert_ids}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bha3ODFlui-s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49928be9-23eb-46e1-e440-17059e50398c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input GPT-2: {'input_ids': tensor([[8001, 9542, 4430,  318,  262, 2003,   13]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n",
            "Input BERT: {'input_ids': tensor([[ 101, 7976, 4454, 2003, 1996, 2925, 1012,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "gpt2_input = gpt2_tokenizer(input_text, return_tensors=\"pt\")\n",
        "bert_input = bert_tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "print(f\"Input GPT-2: {gpt2_input}\")\n",
        "print(f\"Input BERT: {bert_input}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKkNfjivui-t"
      },
      "source": [
        "## Modelos\n",
        "\n",
        "Modelos são as redes neurais que processam os tokens e geram saídas como texto ou embeddings. A Hugging Face disponibiliza uma variedade de modelos, como GPT-2 para geração de texto e BERT para tarefas como busca semântica.\n",
        "\n",
        "Aqui, aprenderemos como carregar e usar esses modelos para diferentes tarefas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTS-LIxzui-t"
      },
      "source": [
        "### Carregando Modelos Pré-Treinados\n",
        "\n",
        "Para começar, vamos carregar modelos pré-treinados, como o GPT-2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNc6yXMFui-v"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "# Carregando o tokenizador GPT-2\n",
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Carregando o modelo GPT-2\n",
        "gpt2_model = GPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=gpt2_tokenizer.eos_token_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HC9qcajzui-v"
      },
      "source": [
        "## Geração de Texto\n",
        "\n",
        "Geração de texto consiste em fornecer uma sequência inicial e permitir que o modelo continue gerando texto a partir dessa entrada. Vamos ver como fazer isso com o GPT-2.\n",
        "\n",
        "A geração de texto é uma das aplicações mais comuns de modelos como o GPT-2, que podem ser usados para completar frases, criar histórias ou mesmo gerar código."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZFEXtGtui-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82dcb8a0-07c3-401f-b0ea-32c641a08537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input IDs: {'input_ids': tensor([[ 818,  257,  995,  810, 9552]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n"
          ]
        }
      ],
      "source": [
        "# Texto de entrada\n",
        "input_text = \"In a world where AI\"\n",
        "\n",
        "# Tokenizando a entrada\n",
        "input_ids = gpt2_tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "print(f\"Input IDs: {input_ids}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8u2vbXjui-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b97c96bb-097a-4a36-9893-ab1f087bddc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 50])\n",
            "Output: tensor([[  818,   257,   995,   810,  9552,   318,   257,  1263,  1917,    11,\n",
            "           340,   338,  1593,   284,  1833,   703,   340,  2499,    13,   198,\n",
            "           198,   464,  1917,   318,   326,  9552,   318,   407,   257,  1917,\n",
            "           379,   477,    13,   632,   338,   257,  1917,   326,   460,   307,\n",
            "         16019,   416,   257,  1256,   286,  1180, 10581,    13,   198,   198]])\n"
          ]
        }
      ],
      "source": [
        "# Gerando o texto\n",
        "output = gpt2_model.generate(**input_ids, max_length=50)\n",
        "\n",
        "print(output.shape)\n",
        "print(f\"Output: {output}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxrRdmkiui-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ddcad0-947c-40e9-e06a-17fb6193fe96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In a world where AI is a big problem, it's important to understand how it works.\n",
            "\n",
            "The problem is that AI is not a problem at all. It's a problem that can be solved by a lot of different approaches.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Decodificando o texto gerado\n",
        "generated_text = gpt2_tokenizer.decode(output[0])\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgURx_toui-x"
      },
      "outputs": [],
      "source": [
        "# Função para completar texto\n",
        "def complete_text(input_text, model=gpt2_model, tokenizer=gpt2_tokenizer, max_length=50):\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
        "    output = model.generate(**input_ids, max_length=max_length)\n",
        "    generated_text = tokenizer.decode(output[0])\n",
        "    return generated_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjrwIG1lui-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c01af7ac-824e-4fc8-f029-7f8c60b4def3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Brazil is a country that has been a beacon of hope for the poor and the working class.\n",
            "\n",
            "The country's economic growth has been a boon for the country's poor, and the country's economy has been a boon for the country's middle\n"
          ]
        }
      ],
      "source": [
        "prediction = complete_text(\"Brazil is\")\n",
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97CN--ogui-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ba5e7c-b2d7-4c7a-92ac-0ecafa9597f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "language\n"
          ]
        }
      ],
      "source": [
        "def generate_next_tokens(input_text, n_tokens=1, model=gpt2_model, tokenizer=gpt2_tokenizer):\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
        "    output = model.generate(input_ids, max_new_tokens=n_tokens)\n",
        "    generated_tokens = output[0][len(input_ids[0]):]  # Extrai apenas os novos tokens gerados\n",
        "    predicted_tokens = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
        "    return predicted_tokens.strip()\n",
        "\n",
        "input_text = \"Brazil is a country. Apple is a fruit. Python is a\"\n",
        "\n",
        "next_token = generate_next_tokens(input_text)\n",
        "print(next_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBblDcRzui-y"
      },
      "source": [
        "## Embeddings de Texto\n",
        "\n",
        "Embeddings de texto são representações vetoriais de palavras ou frases que capturam o significado semântico. Esses embeddings podem ser utilizados em várias tarefas de NLP, como classificação de texto, busca semântica e agrupamento.\n",
        "\n",
        "Nesta seção, utilizaremos o BERT para gerar embeddings de texto e visualizar a similaridade entre diferentes frases. Também introduziremos conceitos como similaridade por cosseno."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Norsa2Ikui-0"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Carregando o tokenizador BERT\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Carregando o modelo BERT\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S89n0XuAui-0"
      },
      "source": [
        "## Capturando Embeddings\n",
        "\n",
        "Predição de embeddings consiste em fornecer um texto e utilizar um modelo encoder para prever a representação vetorial deste texto. Vamos ver como fazer isso com o BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcYE8Lwdui-1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9587930-64ef-43ae-fae6-d52023e637d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 8, 768])\n",
            "torch.Size([1, 768])\n"
          ]
        }
      ],
      "source": [
        "# Texto de entrada\n",
        "text = \"Artificial intelligence is the future.\"\n",
        "input_ids = bert_tokenizer.encode(text, return_tensors=\"pt\")\n",
        "\n",
        "# Obtendo a representação do texto\n",
        "with torch.no_grad():\n",
        "    output = bert_model(input_ids)\n",
        "\n",
        "\n",
        "pooled_output = output.last_hidden_state.mean(dim=1)\n",
        "\n",
        "print(output.last_hidden_state.shape)\n",
        "print(pooled_output.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJfyAYmYui-1"
      },
      "outputs": [],
      "source": [
        "# Função para gerar embeddings usando BERT\n",
        "def get_embedding(text):\n",
        "    input_ids = bert_tokenizer.encode(text, return_tensors=\"pt\")\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(input_ids)\n",
        "    return outputs.last_hidden_state.mean(dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1DNS2R-ui-1"
      },
      "source": [
        "### Medidas de Similaridade\n",
        "\n",
        "A similaridade por cosseno é uma métrica comum utilizada para medir a similaridade entre dois vetores no espaço de embeddings. Ela calcula o cosseno do ângulo entre dois vetores, onde um valor de 1 indica vetores idênticos e um valor de 0 indica vetores ortogonais (sem similaridade).\n",
        "\n",
        "A fórmula da similaridade por cosseno é:\n",
        "\n",
        "$\n",
        "\\text{similaridade}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}\n",
        "$\n",
        "\n",
        "Vamos calcular a similaridade entre diferentes frases usando embeddings gerados por BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MjCEyONui-2"
      },
      "outputs": [],
      "source": [
        "# Exemplo de frases\n",
        "query = \"Artificial intelligence is transforming industries.\"\n",
        "doc1 = \"AI is changing the way we work.\"\n",
        "doc2 = \"Brazil is a country in South America.\"\n",
        "\n",
        "# Gerando embeddings\n",
        "query_embedding = get_embedding(query)\n",
        "doc1_embedding = get_embedding(doc1)\n",
        "doc2_embedding = get_embedding(doc2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_kayUS_ui-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b31a6146-f88d-4169-a1b7-364fa31991bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similaridade com doc1: 0.8325\n",
            "Similaridade com doc2: 0.5219\n"
          ]
        }
      ],
      "source": [
        "# Calculando similaridade por cosseno\n",
        "cos = torch.nn.CosineSimilarity(dim=1)\n",
        "similarity_doc1 = cos(query_embedding, doc1_embedding)\n",
        "similarity_doc2 = cos(query_embedding, doc2_embedding)\n",
        "\n",
        "print(f\"Similaridade com doc1: {similarity_doc1.item():.4f}\")\n",
        "print(f\"Similaridade com doc2: {similarity_doc2.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0enshp7sui-2"
      },
      "source": [
        "## Exercícios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASwn2JWEui-2"
      },
      "source": [
        "### Exercício 1\n",
        "Utilizando GPT-2, crie uma função que preveja o sujeito em uma frase. Por exemplo: Em \"John went to the store\", o sujeito é John."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8YB2b60ui-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea841d1-0f30-471f-853f-6e37e0f142f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "subject\n"
          ]
        }
      ],
      "source": [
        "input_text = (\"'John went to the store'.\" +\n",
        "              \"Went is a verb. To is a preposition. The is an article. Store is a noun. \" +\n",
        "              \"John is a noun. Nouns are called subjects if the noun starts the sentence. Therefore, John is a\")\n",
        "next_token = generate_next_tokens(input_text)\n",
        "print(next_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbDqMfRRui-3"
      },
      "source": [
        "### Exercício 2\n",
        "Em um sistema avançado de busca por livros, você deverá implementar uma função que faça uma busca semântica e retorne os 5 livros mais apropriados de acordo com a consulta do usuário."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LJEaK_iui-3"
      },
      "outputs": [],
      "source": [
        "descriptions = [\n",
        "    \"A tale of love and loss set against the backdrop of war.\",\n",
        "    \"A gripping mystery where nothing is as it seems.\",\n",
        "    \"An epic fantasy adventure in a world of magic and dragons.\",\n",
        "    \"A heartwarming story of friendship and second chances.\",\n",
        "    \"A chilling thriller that will keep you on the edge of your seat.\",\n",
        "    \"A coming-of-age story about finding yourself and your place in the world.\",\n",
        "    \"A historical novel that brings the past to life with vivid detail.\",\n",
        "    \"A suspenseful crime novel where the detective becomes the hunted.\",\n",
        "    \"A dystopian future where one woman's rebellion could change everything.\",\n",
        "    \"A romantic comedy that will make you believe in love again.\",\n",
        "    \"A science fiction saga that explores the limits of human ingenuity.\",\n",
        "    \"A powerful drama about family, secrets, and redemption.\",\n",
        "    \"A journey through time to uncover hidden truths.\",\n",
        "    \"A modern fairy tale where dreams really do come true.\",\n",
        "    \"A dark fantasy filled with intrigue, betrayal, and forbidden magic.\",\n",
        "    \"A psychological thriller that will mess with your mind.\",\n",
        "    \"A poetic exploration of life, love, and everything in between.\",\n",
        "    \"A detective novel where every clue leads to more questions.\",\n",
        "    \"A story of survival and the strength of the human spirit.\",\n",
        "    \"A heart-pounding adventure in a world beyond our own.\",\n",
        "    \"A memoir of a life lived on the edge of society.\",\n",
        "    \"A romance that defies the boundaries of time and space.\",\n",
        "    \"A political thriller set in a world of corruption and power.\",\n",
        "    \"A fantasy epic that weaves together destiny and desire.\",\n",
        "    \"A mystery novel where the past refuses to stay buried.\",\n",
        "    \"A heartwrenching story of love, loss, and letting go.\",\n",
        "    \"A darkly comic tale of life in the absurd.\",\n",
        "    \"A science fiction adventure that questions what it means to be human.\",\n",
        "    \"A historical romance set in a time of revolution and change.\",\n",
        "    \"A supernatural thriller where nightmares come to life.\",\n",
        "    \"A journey of self-discovery in a world that demands conformity.\",\n",
        "    \"A story of forbidden love in a society bound by tradition.\",\n",
        "    \"A fast-paced action novel where every second counts.\",\n",
        "    \"A lyrical exploration of nature, solitude, and the passage of time.\",\n",
        "    \"A detective story where the truth is stranger than fiction.\",\n",
        "    \"A powerful saga of family, loyalty, and betrayal.\",\n",
        "    \"A fantastical journey through a land of myths and legends.\",\n",
        "    \"A tale of revenge, justice, and the price of power.\",\n",
        "    \"A story of hope in the face of overwhelming odds.\",\n",
        "    \"A quirky romance where opposites truly attract.\",\n",
        "    \"A sci-fi thriller that blurs the line between reality and illusion.\",\n",
        "    \"A historical epic that spans generations and continents.\",\n",
        "    \"A crime novel where the line between right and wrong is razor-thin.\",\n",
        "    \"A love story that unfolds in the most unexpected way.\",\n",
        "    \"A philosophical exploration of what it means to live a good life.\",\n",
        "    \"A gripping tale of survival in a post-apocalyptic world.\",\n",
        "    \"A romance that blossoms in the midst of chaos and war.\",\n",
        "    \"A detective novel that unravels the darkest secrets of the human soul.\",\n",
        "    \"A story of redemption and the power of forgiveness.\",\n",
        "    \"A fantasy adventure where a reluctant hero must save the world.\"\n",
        "]\n",
        "\n",
        "input_text = \"A horror novel\"\n",
        "\n",
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_sim = pd.DataFrame(descriptions)\n",
        "df_sim['Similarity'] = 0\n",
        "df_sim['Similarity'].astype(float)\n",
        "df_sim.columns = ['Description', 'Similarity']"
      ],
      "metadata": {
        "id": "4z47DML3DKZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = input()\n",
        "for description in descriptions:\n",
        "    query_embedding = get_embedding(input_text)\n",
        "    doc_embedding = get_embedding(description)\n",
        "    cos = torch.nn.CosineSimilarity(dim=1)\n",
        "    similarity = cos(query_embedding, doc_embedding)\n",
        "    df_sim.loc[df_sim['Description'] == description, 'Similarity'] = similarity.item()\n",
        "\n",
        "df_sim_t5 = df_sim.sort_values(by='Similarity', ascending=False).head(5)\n",
        "df_sim_t5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "IDENBtDgDhUO",
        "outputId": "4ceeab58-a93e-4823-dfd3-37031d2f0700"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a horro novel\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-fd574dc205a1>:7: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '0.5649674534797668' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
            "  df_sim.loc[df_sim['Description'] == description, 'Similarity'] = similarity.item()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Description  Similarity\n",
              "26         A darkly comic tale of life in the absurd.    0.672926\n",
              "48  A story of redemption and the power of forgive...    0.625699\n",
              "31  A story of forbidden love in a society bound b...    0.617379\n",
              "20   A memoir of a life lived on the edge of society.    0.606159\n",
              "24  A mystery novel where the past refuses to stay...    0.597819"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9de4efe4-c45b-47d5-bf31-724f9dde7e81\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>A darkly comic tale of life in the absurd.</td>\n",
              "      <td>0.672926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>A story of redemption and the power of forgive...</td>\n",
              "      <td>0.625699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>A story of forbidden love in a society bound b...</td>\n",
              "      <td>0.617379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>A memoir of a life lived on the edge of society.</td>\n",
              "      <td>0.606159</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>A mystery novel where the past refuses to stay...</td>\n",
              "      <td>0.597819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9de4efe4-c45b-47d5-bf31-724f9dde7e81')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9de4efe4-c45b-47d5-bf31-724f9dde7e81 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9de4efe4-c45b-47d5-bf31-724f9dde7e81');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e50c8151-3272-4c9b-95dc-e50a4413a8a6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e50c8151-3272-4c9b-95dc-e50a4413a8a6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e50c8151-3272-4c9b-95dc-e50a4413a8a6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0621c68b-4a02-4788-9725-e6f017211b2f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_sim_t5')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0621c68b-4a02-4788-9725-e6f017211b2f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_sim_t5');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sim_t5",
              "summary": "{\n  \"name\": \"df_sim_t5\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"A story of redemption and the power of forgiveness.\",\n          \"A mystery novel where the past refuses to stay buried.\",\n          \"A story of forbidden love in a society bound by tradition.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02934385007300904,\n        \"min\": 0.597818911075592,\n        \"max\": 0.6729261875152588,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6256990432739258,\n          0.597818911075592,\n          0.6173791289329529\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}